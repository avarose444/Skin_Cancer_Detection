# Skin_Cancer_Detection
This repository contains code, data, and final figures for a skin cancer classification project using convolutional neural networks (CNNs) and dermatoscopic image analysis.

**Developers:** Lily Ellis, Ava Ferrentino, Lily Saada, and Olivia Matlaga

Inspired by research and applications of deep learning in medical imaging, this project explores automated skin cancer detection using TensorFlow/Keras.

---
We used the [Skin Cancer - 9 Classes (ISIC) dataset](https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic) from Kaggle.
Before running the notebook, upload your `kaggle.json` API key file when prompted (you can generate this from your Kaggle account settings).
You do **not** need to manually download the dataset.  
Before running the notebook, simply upload your `kaggle.json` API key file when prompted.  
*You can generate this from your Kaggle account settings under “API” > Create New Token.*

The FinalSkinClassification.ipynb is our final version.

---
**Figures:**

All figures in this notebook were generated using Python and matplotlib, primarily for data exploration and model interpretability. The following types of visualizations are included:

- Sample Images by Class: One representative image from each of the 9 skin cancer classes was plotted by unbatching the training dataset and selecting a single image per class.

- Clean vs Adversarial Comparisons: For each class, both the original (clean) and adversarially perturbed images were loaded from disk and displayed side-by-side to visualize the effects of adversarial attacks.

- Bar Charts: Class distributions and accuracy metrics for the two models on clean and adversarial data were visualized using matplotlib.pyplot to better understand dataset imbalances and model behavior.

These plots support reproducibility and visual diagnostics during model development.

**Figure Generation:**

- fig1_skindiseases.png was generated by the following code block in FinalSkinClassification.ipynb:

```
Plot one image per class
plt.figure(figsize=(15, 8))
for i, label in enumerate(sorted(class_images)):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(class_images[label])
    plt.title(f"{class_names[label]}")
    plt.axis("off")
plt.suptitle("One Sample per Class", fontsize=16)
plt.tight_layout()
plt.show() 
```

- fig2_cleanadvers.png was generated by the following code block in FinalSkinClassification.ipynb:

```
# Prepare figure
plt.figure(figsize=(15, num_classes * 2))

for i, class_name in enumerate(class_names):
    # clean
    clean_class_path = os.path.join(clean_dir, class_name)
    clean_img_files = sorted([f for f in os.listdir(clean_class_path) if f.startswith("val_clean_")])
    if clean_img_files:
        clean_img = Image.open(os.path.join(clean_class_path, clean_img_files[0])).convert("RGB")
        clean_img = np.array(clean_img).astype(np.float32) / 255.0
        plt.subplot(num_classes, 2, 2*i + 1)
        plt.imshow(clean_img)
        plt.title(f"{class_name} - Clean")
        plt.axis("off")

    # adversarial
    adv_class_path = os.path.join(adv_dir, class_name)
    adv_img_files = sorted([f for f in os.listdir(adv_class_path) if f.startswith("val_adv_")])
    if adv_img_files:
        adv_img = Image.open(os.path.join(adv_class_path, adv_img_files[0])).convert("RGB")
        adv_img = np.array(adv_img).astype(np.float32) / 255.0
        plt.subplot(num_classes, 2, 2*i + 2)
        plt.imshow(adv_img)
        plt.title(f"{class_name} - Adversarial")
        plt.axis("off")

plt.tight_layout()
plt.suptitle("Clean vs Adversarial Examples of Each Class", fontsize=18, y=1.02)
plt.show()
```

- m1vsm2_clean.png was generated by the following code block in FinalSkinClassification.ipynb:

```
# Model1 Clean vs Model2 Clean
x = np.arange(len(class_names))
width = 0.35

plt.figure(figsize=(12, 6))
plt.bar(x - width/2, model1_clean, width=width, label='Model1 Clean')
plt.bar(x + width/2, model2_clean, width=width, label='Model2 Clean')
plt.xticks(x, class_names, rotation=45, ha="right")
plt.ylabel("Accuracy")
plt.title("Model1 vs Model2 (Clean Accuracy per Class)")
plt.ylim(0, 1.0)
plt.legend()
plt.tight_layout()
plt.show()
```

- m1vm2adverse.png was generated by the following code block in FinalSkinClassification.ipynb:

```
# Model1 Adversarial vs Model2 Adversarial
plt.figure(figsize=(12, 6))
plt.bar(x - width/2, original_per_class_adv.values(), width=width, label='Model1 Adversarial')
plt.bar(x + width/2, adv_per_class.values(), width=width, label='Model2 Adversarial')
plt.xticks(x, class_names, rotation=45, ha="right")
plt.ylabel("Accuracy")
plt.title("Model1 vs Model2 (Adversarial Accuracy per Class)")
plt.ylim(0, 1.0)
plt.legend()
plt.tight_layout()
plt.show()
```

---

**References:**

Harsoor, S. (2023). Skin Cancer Detection [Code notebook]. Kaggle. https://www.kaggle.com/code/sharanharsoor/skin-cancer-detection

nodoubttome. (2019). Skin Cancer9 Classes ISIC [Data set]. Kaggle. https://www.kaggle.com/datasets/nodoubttome/skin-cancer9-classesisic

OpenAI. (2025, May 4). ChatGPT response to coding questions [Large language model]. https://chat.openai.com/
